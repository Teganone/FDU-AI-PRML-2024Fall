{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Classification and Clustering\n",
    "\n",
    "In this exercise, you will work with the **Digits** dataset to classify handwritten digits using various machine learning algorithms.\n",
    "\n",
    "Additionally, you'll explore clustering using K-Means and experiment with hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Digits Dataset\n",
    "\n",
    "The **Digits Dataset** consists of 8x8 pixel images of handwritten digits (0â€“9). You will perform classification to predict the correct digit label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Digits dataset\n",
    "from sklearn.datasets import load_digits\n",
    "import pandas as pd\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "print(\"Digits dataset keys: \", digits.keys())\n",
    "print(\"Data count: \", len(digits['data']))\n",
    "print(\"Feature count: \", len(digits['data'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the first digit\n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(digits.images[-1], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "\n",
    "Separate the dataset into features and labels, and split the data into training and testing sets.\n",
    "\n",
    "- Separate the features and target labels.\n",
    "\n",
    "- Split the data into training and test sets using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = digits['data']\n",
    "y = digits['target']\n",
    "\n",
    "# Split the data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of training and test sets\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Decision Tree Classifier\n",
    "\n",
    "In this step, you will train a Decision Tree classifier on the training set.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Use `DecisionTreeClassifier` from `sklearn.tree`.\n",
    "\n",
    "- Fit the model on the training data (`X_train` and `y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# TODO: Create and train a DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "After training, you will evaluate the model's performance on the test set using accuracy, confusion matrix, and classification report.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Predict the test labels using the trained Decision Tree model.\n",
    "\n",
    "- Compute and print the accuracy score.\n",
    "\n",
    "- Use a `confusion matrix` and `classification report` for a more detailed evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# TODO: Predict on the test set\n",
    "\n",
    "# TODO: Compute the accuracy\n",
    "print(\"Accuracy:\")\n",
    "\n",
    "# TODO: Display the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "\n",
    "# TODO: Display a detailed classification report\n",
    "print(\"Classification Report:\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Decision Tree\n",
    "\n",
    "You can visualize the structure of the decision tree to understand how the model makes decisions based on the features.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Use `plot_tree` from `sklearn.tree` to visualize the trained Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# TODO: Visualize the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with Hyperparameters\n",
    "\n",
    "Decision Trees have several hyperparameters that can be tuned to improve performance, such as:\n",
    "\n",
    "- `max_depth`: The maximum depth of the tree.\n",
    "\n",
    "- `min_samples_split`: The minimum number of samples required to split an internal node.\n",
    "\n",
    "- `min_samples_leaf`: The minimum number of samples required to be at a leaf node.\n",
    "\n",
    "**Instructions for Hyperparameter Tuning:**\n",
    "\n",
    "- Use `GridSearchCV` to find the optimal hyperparameters for the Decision Tree.\n",
    "\n",
    "- Try tuning `max_depth`, `min_samples_split`, and `min_samples_leaf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TODO: Define the hyperparameter grid, and use GridSearchCV to find the best parameters\n",
    "\n",
    "# Display the best parameters and best score\n",
    "print(\"Best Params:\")\n",
    "print(\"Best Score:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Using KNN and SVM on the Digits Dataset\n",
    "\n",
    "Now that you've trained and evaluated a Decision Tree classifier, your next task is to try different machine learning algorithms on the same dataset. Specifically, you will implement **K-Nearest Neighbors (KNN)** and **Support Vector Machine (SVM)** classifiers and compare their performance with each other and with the Decision Tree.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Train a K-Nearest Neighbors (KNN) Classifier.\n",
    "\n",
    "    - Use `KNeighborsClassifier` from `sklearn.neighbors`.\n",
    "\n",
    "    - Choose an appropriate number of neighbors (`n_neighbors`).\n",
    "\n",
    "    - Fit the model on the training data (`X_train` and `y_train`).\n",
    "\n",
    "    - Evaluate the model using accuracy, confusion matrix, and classification report, just like you did for the Decision Tree.\n",
    "\n",
    "2. Train a Support Vector Machine (SVM) Classifier.\n",
    "    \n",
    "    - Use `SVC` from `sklearn.svm`.\n",
    "\n",
    "    - Try using different kernel types such as `linear`, `poly`, and `rbf`.\n",
    "    \n",
    "    - Fit the model on the training data (`X_train` and `y_train`).\n",
    "    \n",
    "    - Evaluate the model using accuracy, confusion matrix, and classification report.  \n",
    "\n",
    "3. Compare the performance of the three models (Decision Tree, KNN, and SVM) based on the evaluation metrics.\n",
    "\n",
    "    - Compare the accuracy scores of all three classifiers: Decision Tree, KNN, and SVM.\n",
    "\n",
    "    - Consider how the confusion matrices differ between the models. Are there particular digits that one model predicts better than the others?\n",
    "\n",
    "    - Analyze which model performs best in terms of classification report metrics such as precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code for KNN and SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering with the Digits Dataset\n",
    "\n",
    "In this task, you will perform K-Means clustering on the Digits dataset and analyze how well the clusters correspond to the actual digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply K-Means Clustering\n",
    "\n",
    "Perform K-Means clustering on the dataset without using the labels (since this is unsupervised learning). You will need to cluster the data into 10 groups, corresponding to the digits 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# TODO: Create a KMeans model with 10 clusters\n",
    "\n",
    "# Display the first few cluster labels\n",
    "print(\"Cluster Labels:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Clustering Results\n",
    "\n",
    "Although clustering is unsupervised, you can still compare the predicted clusters to the actual labels in the dataset to evaluate how well the algorithm performed.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Use the actual labels to compute the accuracy or confusion matrix, though this is just a rough comparison (K-Means assigns arbitrary labels to clusters).\n",
    "\n",
    "- Use metrics such as `Adjusted Rand Index (ARI)` or `Normalized Mutual Information (NMI)` to evaluate clustering performance in a more appropriate way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, adjusted_rand_score\n",
    "\n",
    "# TODO: Compare clusters to actual labels\n",
    "\n",
    "# TODO: Use a better metric like Adjusted Rand Index\n",
    "\n",
    "# Optionally, display a confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Clusters\n",
    "\n",
    "You can visualize the clusters by reducing the dimensions of the dataset using techniques like `Principal Component Analysis (PCA`) or `t-SNE`. This will help in visualizing how the data points are grouped into clusters.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Use PCA to reduce the dimensionality of the dataset to 2D for easy visualization.\n",
    "\n",
    "- Plot the clusters in 2D space, colored by their predicted cluster labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Reduce the dimensionality of the dataset using PCA\n",
    "\n",
    "# TODO: Plot the data points with colors corresponding to their clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
